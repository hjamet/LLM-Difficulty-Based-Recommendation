# Active Tasks

## Implement gpt_evaluation.py
- [ ] Core Implementation
  - [ ] Define generate_predictions() function
    - [ ] Add system prompt handling
    - [ ] Track CEFR levels for simplification
    - [ ] Format predictions consistently
  - [ ] Implement main evaluation script
    - [ ] Test both GPT-4o models
    - [ ] Handle zero-shot and fine-tuned cases
    - [ ] Save results properly

- [ ] Testing & Validation
  - [ ] Test with french_difficulty dataset
  - [ ] Test with sentences dataset
  - [ ] Verify prediction format
  - [ ] Validate results storage

## Documentation
- [ ] Document evaluation process
  - [ ] Explain prompt format
  - [ ] Detail CEFR level handling
  - [ ] Describe results structure
- [ ] Add usage examples

# Recently Completed
- [x] Decided on prompt format (2024-03-21)
  - [x] Using system prompt + simple user prompt
  - [x] Consistent with fine-tuning approach
  - [x] Clean separation of instructions/content

- [x] Model Fine-tuning (2024-03-21)
  - [x] Implemented gpt_fine_tuning.py
  - [x] Fine-tuned GPT-4o models
  - [x] Added proper logging
  - [x] Saved model details
