# Leveraging Large Language Models for Foreign Language Learning: Difficulty Estimation, Topic Estimation and Recommendation

## Description ü¶≠

This project contains the code used for our research work described in the article [**Leveraging Large Language Models for Foreign Language Learning: Difficulty Estimation, Topic Estimation and Recommendation**). It contains all the code for our experiments as well as the notebooks used to generate the figures in the article. The aim of the project is to enable :
- The classification of French texts according to their difficulty,
- The classification of French texts according to their subject,
- The recommendation of French texts according to the two previous criteria.
Each of these objectives is dealt with and detailed in a separate folder.

## Installation üêº

### Requirements üê®

This project uses the following tools:
- [Pyenv](https://github.com/pyenv/pyenv-installer) : Python version manager
- [Poetry](https://python-poetry.org/docs/#installation) : Python package manager
Tools that you can install using the following commands:
```bash
curl https://pyenv.run | bash
curl -sSL https://install.python-poetry.org | python3 -
```

Some notebooks also require the following installations:
- MySQL: [Installation](https://dev.mysql.com/doc/mysql-installation-excerpt/5.7/en/)
- A username and password to connect to the [CURNAGL](https://wiki.unil.ch/ci/books/high-performance-computing-hpc/page/curnagl) cluster at the University of Lausanne used for training the heaviest models. However, this code can be run on a local machine without using the [**Slurmray**](https://github.com/hjamet/SLURM_RAY) package.

### With Pyenv & Poetry üêª

Once you have installed the above tools, you can install the project using the following commands:
```bash
pyenv install 3.9.13 # Installs the version of Python used in the project
pyenv local 3.9.13 # Defines the version of Python used in the project
poetry install # Installs project dependencies
```

### Without Pyenv & Poetry üêô

If you don't want to use Pyenv and Poetry, you can install the project dependencies using the following command:
```bash
python -m venv .venv # Creates a virtual environment
source .venv/bin/activate # Activates the virtual environment
pip install -r requirements.txt # Installs project dependencies
```

## Repository Architecture ü¶•

The project is structured as follows:
```
.
‚îú‚îÄ‚îÄ difficulty_estimation (7 notebooks for difficulty estimation)
‚îú‚îÄ‚îÄ text_simplification (8 notebook for text simplification)
‚îú‚îÄ‚îÄ topic_classification (5 notebooks for topic classification)
‚îú‚îÄ‚îÄ recommender systems (4 notebooks for recommendation)
‚îú‚îÄ‚îÄ src (Some frequently used functions and classes)
‚îú‚îÄ‚îÄ figures (The figures generated by the notebooks and used in the article)
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ pyproject.toml
‚îî‚îÄ‚îÄ poetry.lock
```

Notebooks are intended to be executed in alphabetical order. Notebooks in the **"difficulty_estimation "** section are to be executed first, then those in the **"topic_classification "** section and finally those in the **"recommendation "** section.

*Note that executing certain notebooks may cause the following folders to appear:*
```
.
‚îú‚îÄ‚îÄ data (For data storage)
‚îÇ ‚îú‚îÄ‚îÄ raw
‚îÇ ‚îú‚îÄ‚îÄ processed
‚îú‚îÄ‚îÄ results (For storing results)
‚îú‚îÄ‚îÄ scratch (For storing temporary data)
‚îú‚îÄ‚îÄ .slogs (If using Slurmray)
```

### Difficulty Estimation üê≥

1. `a_Datasets` : This notebook allows you to download the data used to train the models. It also prepares the json files needed to train the OpenAI models and provides a cost estimate.
2. `b_OpenAiModelsTraining` : This notebook allows you to train the OpenAI models.
3. `c_OpenAiEvaluation` : This generates the results and metrics for the OpenAI models.
4. `d_OpenSourceModelsTraining` : This notebook is responsible for training the **CamemBERT** and **Mistral** models.
5. `e_OpenSourceEvaluation` : This generates the results and metrics for the **CamemBERT** and **Mistral** models.
6. `f_PairwiseMismatch` : This notebook trains and evaluates the performance of the **ARI**, **GFI** and **FKGL** Readability Indices. It also introduces the **Pairwise Mismatch** metric and evaluates the performance of all previous models on this metric.
7. `g_CreateFigures` : This notebook generates the figures used in the article.

### Topic Classification üê¨

1. `a_DataPreparation`: This notebook is responsible for downloading and pre-processing the data used to train and evaluate the models.
2. `b_Zero-Shot`: This notebook adapts a pre-trained **FlauBERT** model to our subject classification task. It also evaluates the performance of this model as well as that of the **mDeBERTa** Zero-Shot model.
3. `c_OpenAiTopicClassification`: This notebook evaluates the zero-shot performance of the OpenAI models on our subject classification task.
4. `d_FlaubertFineTuned`: This notebook aims to train a **FlauBERT** model on our subject classification task. It also evaluates the performance of this model.
5. `e_CreateFigures`: This notebook generates the figures used in the article.

### Text Simplification ü¶ë

1. `a_DatasetCreation`: This notebook is responsible for creating the dataset used to train the models.
2. `b_FineTuningMistral`: This notebook trains the **Mistral** model on the dataset created in the previous notebook.
3. `c_MistralEvaluation`: This notebook evaluates the performance of the **Mistral** model.
4. `d_Metrics`: This notebook introduces the metrics used to evaluate the performance of the models.
5. `e_OpenAIFineTuning`: This notebook trains the OpenAI models on the dataset created in the first notebook.
6. `f_OpenAIEvaluation`: This notebook evaluates the performance of the OpenAI models.
7. `g_IterativeSimplification`: This notebook evaluates the performance of the iterative simplification method.
8. `h_CreateFigures`: This notebook generates the figures used in the article.

### Recommendations üê†

1. `a_GetZeeguData`: This notebook prepares the Zeegu dataset for recommendation.
2. `b_GenerateEmbeddings`: This notebook generates the ADA and BERT embeddings for all the datasets.
3. `c_Recommendations`: This notebook applies the recommender systems on all datasets. 
4. `d_Graphic`: This notebook generates a graph depicting how the performance of LightGCN evolves as the number of layers increases, specifically for the Zeegu dataset.
